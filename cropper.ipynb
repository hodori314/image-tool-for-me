{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 134)\n",
      "4 4 64 64\n",
      "4 68 64 128\n",
      "(68, 134)\n",
      "4 4 64 64\n",
      "4 68 64 128\n",
      "(68, 134)\n",
      "4 4 64 64\n",
      "4 68 64 128\n",
      "(68, 134)\n",
      "4 4 64 64\n",
      "4 68 64 128\n"
     ]
    }
   ],
   "source": [
    "# for 1 ipc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "ipc = 1\n",
    "exp = [0, 1, 2, 3 ]\n",
    "iter = 1000\n",
    "\n",
    "for e in exp:\n",
    "    image1 = Image.open('origin/vis_DC_CelebA_ConvNet_%dipc_exp%d_iter%d.png'%(ipc, e, iter))\n",
    "\n",
    "    #이미지의 크기 출력\n",
    "    print(image1.size)\n",
    "    width = 64\n",
    "    length = 64\n",
    " \n",
    "    for i in range(2):\n",
    "        left = 4 \n",
    "        up   = 4 + (i) *length\n",
    "\n",
    "        right =  length\n",
    "        down =  (i+1) *length\n",
    "        print(left, up, right, down)\n",
    "\n",
    "        # ex. crop(left, up, rigth, down)\n",
    "        croppedImage=image1.crop((left, up, right, down))\n",
    "        # print(\"잘려진 사진 크기 :\",croppedImage.size)\n",
    "\n",
    "        if e==0:\n",
    "            croppedImage.save(f'GM2ipc/G-train/%d/%d%d.png'%(i,e,i))\n",
    "        else:\n",
    "            croppedImage.save(f'GM2ipc/G-valid/%d/%d%d.png'%(i,e,i))\n",
    "            # pass\n",
    "        # croppedImage.save(f'GM2ipc/G-valid/%d/%d%d.png'%(i,e,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 342)\n",
      "2 2 34 34\n",
      "2 36 34 68\n",
      "2 70 34 102\n",
      "2 104 34 136\n",
      "2 138 34 170\n",
      "2 172 34 204\n",
      "2 206 34 238\n",
      "2 240 34 272\n",
      "2 274 34 306\n",
      "2 308 34 340\n",
      "36 2 68 34\n",
      "36 36 68 68\n",
      "36 70 68 102\n",
      "36 104 68 136\n",
      "36 138 68 170\n",
      "36 172 68 204\n",
      "36 206 68 238\n",
      "36 240 68 272\n",
      "36 274 68 306\n",
      "36 308 68 340\n",
      "70 2 102 34\n",
      "70 36 102 68\n",
      "70 70 102 102\n",
      "70 104 102 136\n",
      "70 138 102 170\n",
      "70 172 102 204\n",
      "70 206 102 238\n",
      "70 240 102 272\n",
      "70 274 102 306\n",
      "70 308 102 340\n",
      "104 2 136 34\n",
      "104 36 136 68\n",
      "104 70 136 102\n",
      "104 104 136 136\n",
      "104 138 136 170\n",
      "104 172 136 204\n",
      "104 206 136 238\n",
      "104 240 136 272\n",
      "104 274 136 306\n",
      "104 308 136 340\n",
      "138 2 170 34\n",
      "138 36 170 68\n",
      "138 70 170 102\n",
      "138 104 170 136\n",
      "138 138 170 170\n",
      "138 172 170 204\n",
      "138 206 170 238\n",
      "138 240 170 272\n",
      "138 274 170 306\n",
      "138 308 170 340\n",
      "172 2 204 34\n",
      "172 36 204 68\n",
      "172 70 204 102\n",
      "172 104 204 136\n",
      "172 138 204 170\n",
      "172 172 204 204\n",
      "172 206 204 238\n",
      "172 240 204 272\n",
      "172 274 204 306\n",
      "172 308 204 340\n",
      "206 2 238 34\n",
      "206 36 238 68\n",
      "206 70 238 102\n",
      "206 104 238 136\n",
      "206 138 238 170\n",
      "206 172 238 204\n",
      "206 206 238 238\n",
      "206 240 238 272\n",
      "206 274 238 306\n",
      "206 308 238 340\n",
      "240 2 272 34\n",
      "240 36 272 68\n",
      "240 70 272 102\n",
      "240 104 272 136\n",
      "240 138 272 170\n",
      "240 172 272 204\n",
      "240 206 272 238\n",
      "240 240 272 272\n",
      "240 274 272 306\n",
      "240 308 272 340\n",
      "274 2 306 34\n",
      "274 36 306 68\n",
      "274 70 306 102\n",
      "274 104 306 136\n",
      "274 138 306 170\n",
      "274 172 306 204\n",
      "274 206 306 238\n",
      "274 240 306 272\n",
      "274 274 306 306\n",
      "274 308 306 340\n",
      "308 2 340 34\n",
      "308 36 340 68\n",
      "308 70 340 102\n",
      "308 104 340 136\n",
      "308 138 340 170\n",
      "308 172 340 204\n",
      "308 206 340 238\n",
      "308 240 340 272\n",
      "308 274 340 306\n",
      "308 308 340 340\n"
     ]
    }
   ],
   "source": [
    "# for ipc more than 1\n",
    "from PIL import Image\n",
    "\n",
    "ipc = 10\n",
    "exp = [0 ]\n",
    "iter = 0\n",
    "\n",
    "for e in exp:\n",
    "    image1 = Image.open('origin/vis_DC_CIFAR10_ConvNet_%dipc_exp%d_iter%d.png'%(ipc, e, iter))\n",
    "\n",
    "    #이미지의 크기 출력\n",
    "    print(image1.size)\n",
    "    width = 34\n",
    "    length = 34\n",
    "    for j in range(ipc):\n",
    "        for i in range(10):\n",
    "            left = 2 + (j) * width\n",
    "            up   = 2 + (i) *length\n",
    "\n",
    "            right = (j+1) * width\n",
    "            down =  (i+1) *length\n",
    "            print(left, up, right, down)\n",
    "\n",
    "            # ex. crop(left, up, rigth, down)\n",
    "            croppedImage=image1.crop((left, up, right, down))\n",
    "            # print(\"잘려진 사진 크기 :\",croppedImage.size)\n",
    "\n",
    "            if e==4:\n",
    "                croppedImage.save(f'GM100ipc/GM2ipc-valid/%d/%d%d.png'%(i,e,i))\n",
    "                \n",
    "            else:\n",
    "                croppedImage.save(f'GM100/%d/%d%d.png'%(i,j,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "selected_indices = [989, 16103, 9745, 43520, 10860, 20737, 20953, 9129, 44840, 26979, 41081, 14762, 45686, 43308, 27682, 10884, 8785, 3670, 39376, 19380]\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='~/data/CIFAR10', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "subset_dataset = torch.utils.data.Subset(trainset, selected_indices)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(subset_dataset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "channel = 3\n",
    "im_size = (32, 32)\n",
    "num_classes = 2\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "transform=transforms.Compose([\n",
    "                        transforms.Resize(im_size),\n",
    "                        transforms.CenterCrop(im_size),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "selected_indices = [33, 54, 143, 207, 30, 89, 182, 141, 88, 11, 119, 204, 74, 105, 178, 128, 71, 33, 197, 177]\n",
    "\n",
    "temp_set = torchvision.datasets.ImageFolder(root='~/data/celebA-condensed/gender', transform=transform)\n",
    "origin_set = torch.utils.data.Subset(temp_set, selected_indices)\n",
    "origin_loader = torch.utils.data.DataLoader(origin_set, batch_size=1,\n",
    "                                    shuffle=False, num_workers=0)\n",
    "\n",
    "def imshow(img, i):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.savefig('result/%s.png'%(i), bbox_inches='tight')\n",
    "\n",
    "for i, data in enumerate(origin_loader):\n",
    "    image, label = data\n",
    "    imshow(torchvision.utils.make_grid(image), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n"
     ]
    }
   ],
   "source": [
    "# for ipc more than 1\n",
    "from PIL import Image\n",
    "\n",
    "for i in range(20):\n",
    "    image1 = Image.open('result/%d.png'%(i))\n",
    "\n",
    "    #이미지의 크기 출력\n",
    "    print(image1.size)\n",
    "    # width = 34\n",
    "    # length = 34\n",
    "    # for j in range(ipc):\n",
    "    #     for i in range(10):\n",
    "    #         left = 2 + (j) * width\n",
    "    #         up   = 2 + (i) *length\n",
    "\n",
    "    #         right = (j+1) * width\n",
    "    #         down =  (i+1) *length\n",
    "    #         print(left, up, right, down)\n",
    "\n",
    "    #         # ex. crop(left, up, rigth, down)\n",
    "    #         croppedImage=image1.crop((left, up, right, down))\n",
    "    #         # print(\"잘려진 사진 크기 :\",croppedImage.size)\n",
    "    #         croppedImage.save(f'GM10/%d/%d%d.png'%(i,j,i))\n",
    "\n",
    "\n",
    "    not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unpack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
