{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 342)\n",
      "2 2 34 34\n",
      "2 36 34 68\n",
      "2 70 34 102\n",
      "2 104 34 136\n",
      "2 138 34 170\n",
      "2 172 34 204\n",
      "2 206 34 238\n",
      "2 240 34 272\n",
      "2 274 34 306\n",
      "2 308 34 340\n",
      "(36, 342)\n",
      "2 2 34 34\n",
      "2 36 34 68\n",
      "2 70 34 102\n",
      "2 104 34 136\n",
      "2 138 34 170\n",
      "2 172 34 204\n",
      "2 206 34 238\n",
      "2 240 34 272\n",
      "2 274 34 306\n",
      "2 308 34 340\n",
      "(36, 342)\n",
      "2 2 34 34\n",
      "2 36 34 68\n",
      "2 70 34 102\n",
      "2 104 34 136\n",
      "2 138 34 170\n",
      "2 172 34 204\n",
      "2 206 34 238\n",
      "2 240 34 272\n",
      "2 274 34 306\n",
      "2 308 34 340\n",
      "(36, 342)\n",
      "2 2 34 34\n",
      "2 36 34 68\n",
      "2 70 34 102\n",
      "2 104 34 136\n",
      "2 138 34 170\n",
      "2 172 34 204\n",
      "2 206 34 238\n",
      "2 240 34 272\n",
      "2 274 34 306\n",
      "2 308 34 340\n",
      "(36, 342)\n",
      "2 2 34 34\n",
      "2 36 34 68\n",
      "2 70 34 102\n",
      "2 104 34 136\n",
      "2 138 34 170\n",
      "2 172 34 204\n",
      "2 206 34 238\n",
      "2 240 34 272\n",
      "2 274 34 306\n",
      "2 308 34 340\n"
     ]
    }
   ],
   "source": [
    "# for 1 ipc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "ipc = 1\n",
    "exp = [0, 1, 2 ,3, 4 ]\n",
    "iter = 1000\n",
    "\n",
    "for e in exp:\n",
    "    image1 = Image.open('origin/vis_DC_CIFAR10_ConvNet_%dipc_exp%d_iter%d.png'%(ipc, e, iter))\n",
    "\n",
    "    #이미지의 크기 출력\n",
    "    print(image1.size)\n",
    "    width = 34\n",
    "    length = 34\n",
    " \n",
    "    for i in range(10):\n",
    "        left = 2 \n",
    "        up   = 2 + (i) *length\n",
    "\n",
    "        right =  length\n",
    "        down =  (i+1) *length\n",
    "        print(left, up, right, down)\n",
    "\n",
    "        # ex. crop(left, up, rigth, down)\n",
    "        croppedImage=image1.crop((left, up, right, down))\n",
    "        # print(\"잘려진 사진 크기 :\",croppedImage.size)\n",
    "\n",
    "        # if e==0:\n",
    "        #     croppedImage.save(f'GM500ipc/G-valid/%d/%d%d.png'%(i,e,i))\n",
    "        # else:\n",
    "        #     # croppedImage.save(f'GM2ipc/G-train/%d/%d%d.png'%(i,e,i))\n",
    "        #     pass\n",
    "        croppedImage.save(f'GM2ipc/G-valid/%d/%d%d.png'%(i,e,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 342)\n",
      "2 2 34 34\n",
      "2 36 34 68\n",
      "2 70 34 102\n",
      "2 104 34 136\n",
      "2 138 34 170\n",
      "2 172 34 204\n",
      "2 206 34 238\n",
      "2 240 34 272\n",
      "2 274 34 306\n",
      "2 308 34 340\n",
      "36 2 68 34\n",
      "36 36 68 68\n",
      "36 70 68 102\n",
      "36 104 68 136\n",
      "36 138 68 170\n",
      "36 172 68 204\n",
      "36 206 68 238\n",
      "36 240 68 272\n",
      "36 274 68 306\n",
      "36 308 68 340\n",
      "70 2 102 34\n",
      "70 36 102 68\n",
      "70 70 102 102\n",
      "70 104 102 136\n",
      "70 138 102 170\n",
      "70 172 102 204\n",
      "70 206 102 238\n",
      "70 240 102 272\n",
      "70 274 102 306\n",
      "70 308 102 340\n",
      "104 2 136 34\n",
      "104 36 136 68\n",
      "104 70 136 102\n",
      "104 104 136 136\n",
      "104 138 136 170\n",
      "104 172 136 204\n",
      "104 206 136 238\n",
      "104 240 136 272\n",
      "104 274 136 306\n",
      "104 308 136 340\n",
      "138 2 170 34\n",
      "138 36 170 68\n",
      "138 70 170 102\n",
      "138 104 170 136\n",
      "138 138 170 170\n",
      "138 172 170 204\n",
      "138 206 170 238\n",
      "138 240 170 272\n",
      "138 274 170 306\n",
      "138 308 170 340\n",
      "172 2 204 34\n",
      "172 36 204 68\n",
      "172 70 204 102\n",
      "172 104 204 136\n",
      "172 138 204 170\n",
      "172 172 204 204\n",
      "172 206 204 238\n",
      "172 240 204 272\n",
      "172 274 204 306\n",
      "172 308 204 340\n",
      "206 2 238 34\n",
      "206 36 238 68\n",
      "206 70 238 102\n",
      "206 104 238 136\n",
      "206 138 238 170\n",
      "206 172 238 204\n",
      "206 206 238 238\n",
      "206 240 238 272\n",
      "206 274 238 306\n",
      "206 308 238 340\n",
      "240 2 272 34\n",
      "240 36 272 68\n",
      "240 70 272 102\n",
      "240 104 272 136\n",
      "240 138 272 170\n",
      "240 172 272 204\n",
      "240 206 272 238\n",
      "240 240 272 272\n",
      "240 274 272 306\n",
      "240 308 272 340\n",
      "274 2 306 34\n",
      "274 36 306 68\n",
      "274 70 306 102\n",
      "274 104 306 136\n",
      "274 138 306 170\n",
      "274 172 306 204\n",
      "274 206 306 238\n",
      "274 240 306 272\n",
      "274 274 306 306\n",
      "274 308 306 340\n",
      "308 2 340 34\n",
      "308 36 340 68\n",
      "308 70 340 102\n",
      "308 104 340 136\n",
      "308 138 340 170\n",
      "308 172 340 204\n",
      "308 206 340 238\n",
      "308 240 340 272\n",
      "308 274 340 306\n",
      "308 308 340 340\n"
     ]
    }
   ],
   "source": [
    "# for ipc more than 1\n",
    "from PIL import Image\n",
    "\n",
    "ipc = 10\n",
    "exp = [0 ]\n",
    "iter = 0\n",
    "\n",
    "for e in exp:\n",
    "    image1 = Image.open('origin/vis_DC_CIFAR10_ConvNet_%dipc_exp%d_iter%d.png'%(ipc, e, iter))\n",
    "\n",
    "    #이미지의 크기 출력\n",
    "    print(image1.size)\n",
    "    width = 34\n",
    "    length = 34\n",
    "    for j in range(ipc):\n",
    "        for i in range(10):\n",
    "            left = 2 + (j) * width\n",
    "            up   = 2 + (i) *length\n",
    "\n",
    "            right = (j+1) * width\n",
    "            down =  (i+1) *length\n",
    "            print(left, up, right, down)\n",
    "\n",
    "            # ex. crop(left, up, rigth, down)\n",
    "            croppedImage=image1.crop((left, up, right, down))\n",
    "            # print(\"잘려진 사진 크기 :\",croppedImage.size)\n",
    "\n",
    "            if e==4:\n",
    "                croppedImage.save(f'GM2ipc/GM2ipc-valid/%d/%d%d.png'%(i,e,i))\n",
    "                \n",
    "            else:\n",
    "                croppedImage.save(f'GM10/%d/%d%d.png'%(i,j,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/guest-yhj/image-tool-for-me/cropper.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlportal1.postech.ac.kr/home/guest-yhj/image-tool-for-me/cropper.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlportal1.postech.ac.kr/home/guest-yhj/image-tool-for-me/cropper.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtransforms\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlportal1.postech.ac.kr/home/guest-yhj/image-tool-for-me/cropper.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlportal1.postech.ac.kr/home/guest-yhj/image-tool-for-me/cropper.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     [transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmlportal1.postech.ac.kr/home/guest-yhj/image-tool-for-me/cropper.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m      transforms\u001b[39m.\u001b[39;49mResize(\u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlportal1.postech.ac.kr/home/guest-yhj/image-tool-for-me/cropper.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m      transforms\u001b[39m.\u001b[39mNormalize((\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m), (\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m))])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlportal1.postech.ac.kr/home/guest-yhj/image-tool-for-me/cropper.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m selected_indices \u001b[39m=\u001b[39m [\u001b[39m989\u001b[39m, \u001b[39m16103\u001b[39m, \u001b[39m9745\u001b[39m, \u001b[39m43520\u001b[39m, \u001b[39m10860\u001b[39m, \u001b[39m20737\u001b[39m, \u001b[39m20953\u001b[39m, \u001b[39m9129\u001b[39m, \u001b[39m44840\u001b[39m, \u001b[39m26979\u001b[39m, \u001b[39m41081\u001b[39m, \u001b[39m14762\u001b[39m, \u001b[39m45686\u001b[39m, \u001b[39m43308\u001b[39m, \u001b[39m27682\u001b[39m, \u001b[39m10884\u001b[39m, \u001b[39m8785\u001b[39m, \u001b[39m3670\u001b[39m, \u001b[39m39376\u001b[39m, \u001b[39m19380\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlportal1.postech.ac.kr/home/guest-yhj/image-tool-for-me/cropper.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m trainset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mCIFAR10(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m~/data/CIFAR10\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlportal1.postech.ac.kr/home/guest-yhj/image-tool-for-me/cropper.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m                                         download\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, transform\u001b[39m=\u001b[39mtransform)\n",
      "File \u001b[0;32m~/.conda/envs/unpack/lib/python3.8/site-packages/torchvision/transforms/transforms.py:348\u001b[0m, in \u001b[0;36mResize.__init__\u001b[0;34m(self, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_size \u001b[39m=\u001b[39m max_size\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(interpolation, \u001b[39mint\u001b[39m):\n\u001b[0;32m--> 348\u001b[0m     interpolation \u001b[39m=\u001b[39m _interpolation_modes_from_int(interpolation)\n\u001b[1;32m    350\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterpolation \u001b[39m=\u001b[39m interpolation\n\u001b[1;32m    351\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mantialias \u001b[39m=\u001b[39m antialias\n",
      "File \u001b[0;32m~/.conda/envs/unpack/lib/python3.8/site-packages/torchvision/transforms/functional.py:48\u001b[0m, in \u001b[0;36m_interpolation_modes_from_int\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_interpolation_modes_from_int\u001b[39m(i: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m InterpolationMode:\n\u001b[1;32m     40\u001b[0m     inverse_modes_mapping \u001b[39m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m         \u001b[39m0\u001b[39m: InterpolationMode\u001b[39m.\u001b[39mNEAREST,\n\u001b[1;32m     42\u001b[0m         \u001b[39m2\u001b[39m: InterpolationMode\u001b[39m.\u001b[39mBILINEAR,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[39m1\u001b[39m: InterpolationMode\u001b[39m.\u001b[39mLANCZOS,\n\u001b[1;32m     47\u001b[0m     }\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m inverse_modes_mapping[i]\n",
      "\u001b[0;31mKeyError\u001b[0m: 32"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "selected_indices = [989, 16103, 9745, 43520, 10860, 20737, 20953, 9129, 44840, 26979, 41081, 14762, 45686, 43308, 27682, 10884, 8785, 3670, 39376, 19380]\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='~/data/CIFAR10', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "subset_dataset = torch.utils.data.Subset(trainset, selected_indices)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(subset_dataset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 이미지를 보여주기 위한 함수\n",
    "\n",
    "\n",
    "def imshow(img, i):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.savefig('result/%s.png'%(i), bbox_inches='tight')\n",
    "\n",
    "for i, data in enumerate(trainloader):\n",
    "    image, label = data\n",
    "    imshow(torchvision.utils.make_grid(image), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n",
      "(389, 389)\n"
     ]
    }
   ],
   "source": [
    "# for ipc more than 1\n",
    "from PIL import Image\n",
    "\n",
    "for i in range(20):\n",
    "    image1 = Image.open('result/%d.png'%(i))\n",
    "\n",
    "    #이미지의 크기 출력\n",
    "    print(image1.size)\n",
    "    # width = 34\n",
    "    # length = 34\n",
    "    # for j in range(ipc):\n",
    "    #     for i in range(10):\n",
    "    #         left = 2 + (j) * width\n",
    "    #         up   = 2 + (i) *length\n",
    "\n",
    "    #         right = (j+1) * width\n",
    "    #         down =  (i+1) *length\n",
    "    #         print(left, up, right, down)\n",
    "\n",
    "    #         # ex. crop(left, up, rigth, down)\n",
    "    #         croppedImage=image1.crop((left, up, right, down))\n",
    "    #         # print(\"잘려진 사진 크기 :\",croppedImage.size)\n",
    "    #         croppedImage.save(f'GM10/%d/%d%d.png'%(i,j,i))\n",
    "\n",
    "\n",
    "    not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unpack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
